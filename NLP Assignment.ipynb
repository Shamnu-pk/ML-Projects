{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e77a91-4991-4135-b883-392fa1a2c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"/Users/shamnas/Downloads/nlp_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0985b4e-64e6-4da8-9975-a2d4b46b79d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>i begun to feel distressed for you</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>i left feeling annoyed and angry thinking that...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>i were to ever get married i d have everything...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>i feel reluctant in applying there because i w...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>i just wanted to apologize to you because i fe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5937 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "0     i seriously hate one subject to death but now ...    fear\n",
       "1                    im so full of life i feel appalled   anger\n",
       "2     i sit here to write i start to dig out my feel...    fear\n",
       "3     ive been really angry with r and i feel like a...     joy\n",
       "4     i feel suspicious if there is no one outside l...    fear\n",
       "...                                                 ...     ...\n",
       "5932                 i begun to feel distressed for you    fear\n",
       "5933  i left feeling annoyed and angry thinking that...   anger\n",
       "5934  i were to ever get married i d have everything...     joy\n",
       "5935  i feel reluctant in applying there because i w...    fear\n",
       "5936  i just wanted to apologize to you because i fe...   anger\n",
       "\n",
       "[5937 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59cea804-555b-425e-b72d-18d0994b1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['Comment']\n",
    "y=data['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e02227f-0f9e-4bf6-a20b-03d4d940a443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shamnas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/shamnas/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2e7b5-c696-4c7a-918d-35adbf87d0c4",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97fa5d47-b7b8-48ee-a83b-1dd2de4b39d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i seriously hate one subject to death but now ...\n",
       "1                      im so full of life i feel appalled\n",
       "2       i sit here to write i start to dig out my feel...\n",
       "3       ive been really angry with r and i feel like a...\n",
       "4       i feel suspicious if there is no one outside l...\n",
       "                              ...                        \n",
       "5932                   i begun to feel distressed for you\n",
       "5933    i left feeling annoyed and angry thinking that...\n",
       "5934    i were to ever get married i d have everything...\n",
       "5935    i feel reluctant in applying there because i w...\n",
       "5936    i just wanted to apologize to you because i fe...\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc7ac44-ac40-4bac-b60f-5debb99fb61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [i, seriously, hate, one, subject, to, death, ...\n",
       "1             [im, so, full, of, life, i, feel, appalled]\n",
       "2       [i, sit, here, to, write, i, start, to, dig, o...\n",
       "3       [ive, been, really, angry, with, r, and, i, fe...\n",
       "4       [i, feel, suspicious, if, there, is, no, one, ...\n",
       "                              ...                        \n",
       "5932           [i, begun, to, feel, distressed, for, you]\n",
       "5933    [i, left, feeling, annoyed, and, angry, thinki...\n",
       "5934    [i, were, to, ever, get, married, i, d, have, ...\n",
       "5935    [i, feel, reluctant, in, applying, there, beca...\n",
       "5936    [i, just, wanted, to, apologize, to, you, beca...\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "x_tokenized=x.apply(word_tokenize)\n",
    "x_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985fbe18-a0b1-4a44-aab8-d5200c1c27f7",
   "metadata": {},
   "source": [
    "# Lowercase tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "626cc8c6-ba85-4e94-98b0-afffd03f91d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [i, seriously, hate, one, subject, to, death, ...\n",
       "1             [im, so, full, of, life, i, feel, appalled]\n",
       "2       [i, sit, here, to, write, i, start, to, dig, o...\n",
       "3       [ive, been, really, angry, with, r, and, i, fe...\n",
       "4       [i, feel, suspicious, if, there, is, no, one, ...\n",
       "                              ...                        \n",
       "5932           [i, begun, to, feel, distressed, for, you]\n",
       "5933    [i, left, feeling, annoyed, and, angry, thinki...\n",
       "5934    [i, were, to, ever, get, married, i, d, have, ...\n",
       "5935    [i, feel, reluctant, in, applying, there, beca...\n",
       "5936    [i, just, wanted, to, apologize, to, you, beca...\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lowercase=x_tokenized.apply(lambda tokens:[token.lower() for token in tokens])\n",
    "x_lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237950e-3c6a-4a06-88c7-7a94927c2aa8",
   "metadata": {},
   "source": [
    "# Stopwords removel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f91ff7d2-4275-4126-ad05-b1722a29cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shamnas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37720224-5e2a-4ecd-bc9e-f95d99e2deec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38992539-aea7-4d1a-88de-e8d731bf74da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [seriously, hate, one, subject, death, feel, r...\n",
       "1                        [im, full, life, feel, appalled]\n",
       "2       [sit, write, start, dig, feelings, think, afra...\n",
       "3       [ive, really, angry, r, feel, like, idiot, tru...\n",
       "4       [feel, suspicious, one, outside, like, rapture...\n",
       "                              ...                        \n",
       "5932                            [begun, feel, distressed]\n",
       "5933    [left, feeling, annoyed, angry, thinking, cent...\n",
       "5934    [ever, get, married, everything, ready, offer,...\n",
       "5935    [feel, reluctant, applying, want, able, find, ...\n",
       "5936    [wanted, apologize, feel, like, heartless, bitch]\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stopwords=x_lowercase.apply(lambda i:[word for word in i if word not in stop_words])\n",
    "x_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4dede-2d02-447c-a40d-125558fbabca",
   "metadata": {},
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2cc1ec8-fff1-4925-8c70-0ecce0a1928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/shamnas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/shamnas/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd7e38e8-5d54-4567-9c96-8a68f66bfdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [seriously, hate, one, subject, death, feel, r...\n",
       "1                        [im, full, life, feel, appalled]\n",
       "2       [sit, write, start, dig, feeling, think, afrai...\n",
       "3       [ive, really, angry, r, feel, like, idiot, tru...\n",
       "4       [feel, suspicious, one, outside, like, rapture...\n",
       "                              ...                        \n",
       "5932                            [begun, feel, distressed]\n",
       "5933    [left, feeling, annoyed, angry, thinking, cent...\n",
       "5934    [ever, get, married, everything, ready, offer,...\n",
       "5935    [feel, reluctant, applying, want, able, find, ...\n",
       "5936    [wanted, apologize, feel, like, heartless, bitch]\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizar=WordNetLemmatizer()\n",
    "lemmatized_tokens=x_stopwords.apply(lambda i:[lemmatizar.lemmatize(word) for word in i])\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82056e61-b581-4bb8-8bea-b13532c6d976",
   "metadata": {},
   "source": [
    "# Avoid punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd1cdf06-181b-42bc-a40a-bce20007f88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07a233c1-9927-4f73-8cdb-bc93bf0b7d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [seriously, hate, one, subject, death, feel, r...\n",
       "1                        [im, full, life, feel, appalled]\n",
       "2       [sit, write, start, dig, feeling, think, afrai...\n",
       "3       [ive, really, angry, r, feel, like, idiot, tru...\n",
       "4       [feel, suspicious, one, outside, like, rapture...\n",
       "                              ...                        \n",
       "5932                            [begun, feel, distressed]\n",
       "5933    [left, feeling, annoyed, angry, thinking, cent...\n",
       "5934    [ever, get, married, everything, ready, offer,...\n",
       "5935    [feel, reluctant, applying, want, able, find, ...\n",
       "5936    [wanted, apologize, feel, like, heartless, bitch]\n",
       "Name: Comment, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_punct=lemmatized_tokens.apply(lambda i:[word for word in i if word not in string.punctuation])\n",
    "tokens_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b2f6d-4228-411f-a2ca-ec5a8f385e83",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e1c2d49-0d69-4eb6-90da-856a89d85371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "x_vectorized=vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "439c43ef-d435-470a-96ee-5136f73852fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cb1130e-0e9c-443f-bd32-bddd3463de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_vectorized,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677569c8-b53c-457b-ab59-9be15a22d826",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40f50d9b-046a-4cb1-8274-12fe6b17ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "896352ad-f879-4b9f-a6ac-2b0eab0a55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model=MultinomialNB()\n",
    "nb_model.fit(x_train,y_train)\n",
    "y_pred_nb=nb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50d21fa5-c257-4257-af0d-c55c0afcdcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.8939393939393939\n",
      "Classification report for Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.92      0.90       392\n",
      "        fear       0.88      0.92      0.90       416\n",
      "         joy       0.92      0.84      0.88       380\n",
      "\n",
      "    accuracy                           0.89      1188\n",
      "   macro avg       0.90      0.89      0.89      1188\n",
      "weighted avg       0.89      0.89      0.89      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes accuracy:\",accuracy_score(y_test,y_pred_nb))\n",
    "print(\"Classification report for Naive Bayes:\\n\",classification_report(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3b289-26c6-48aa-a68a-359552a5f9bb",
   "metadata": {},
   "source": [
    "# Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ff816e0-7ca6-4c13-b5bd-f593e52f143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model=SVC(kernel=\"linear\")\n",
    "svm_model.fit(x_train,y_train)\n",
    "y_pred_svm=svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e693442-8c81-44a5-bbfd-3fdbe21ce5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy: 0.9486531986531986\n",
      "Classification report for svm:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.92      0.96      0.94       392\n",
      "        fear       0.97      0.92      0.95       416\n",
      "         joy       0.96      0.96      0.96       380\n",
      "\n",
      "    accuracy                           0.95      1188\n",
      "   macro avg       0.95      0.95      0.95      1188\n",
      "weighted avg       0.95      0.95      0.95      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"svm accuracy:\",accuracy_score(y_test,y_pred_svm))\n",
    "print('Classification report for svm:\\n',classification_report(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4796fcf1-7bff-42e9-94e9-7a71c22476ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for Naive Bayes:\n",
      " [[359  21  12]\n",
      " [ 18 382  16]\n",
      " [ 30  29 321]]\n",
      "confusion matrix for svm:\n",
      " [[377   7   8]\n",
      " [ 24 384   8]\n",
      " [  9   5 366]]\n",
      "Naive Bayes accuracy: 0.8939393939393939\n",
      "svm accuracy: 0.9486531986531986\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix for Naive Bayes:\\n', confusion_matrix(y_test,y_pred_nb))\n",
    "\n",
    "print('confusion matrix for svm:\\n', confusion_matrix(y_test,y_pred_svm))\n",
    "\n",
    "print('Naive Bayes accuracy:', accuracy_score(y_test,y_pred_nb))\n",
    "\n",
    "print('svm accuracy:', accuracy_score(y_test,y_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
